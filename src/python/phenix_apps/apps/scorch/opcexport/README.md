# opcexport Component

The `opcexport` component is a component used to dump data from the OPC server to Elasticsearch, into a dated index named `opc-dirty-*` (e.g. `opc-dirty-2025.03.18`). It it should be used in tandem with the `sceptre` app, and won't work without it. It also requires the `assetDir` attribute be set in the `sceptre` app's metadata, to the path of the experiment source files (e.g. `assetDir: /phenix/topologies/my_topo/`).

It is assumed that Elasticsearch already exists. This can either be a VM inside your experiment or Elasticsearch on your host. If it is the latter, then you need to make sure you have the networking correctly configured for the OPC server within your experiment to reach the elastic endpoint on your host. If the `tap` app is used, and the Elasticsearch server is not `172.16.0.254`, then routes will be automatically added to enable communication from the OPC to Elasticsearch.

This component also assumes you have a valid OPC configuration file (either hand made or generated with the `sceptre` app), since the component needs be able to read it to understand the channels/devices/tags of the data in the OPC server that it will be writing to Elasticsearch.

> NOTE: this currently reads tag information from a XML file generated by TOP server. Support for other OPC servers or a generic format could be added in the future.

> NOTE: There is not yet an implementation to apply to more than one OPC server in a given experiment. Easy to extend to do this, just hasn't been done yet... I suppose if you really needed to do this, one `opcexport` component could be created for each OPC server.

```
type: opcexport
exe:  phenix-scorch-component-opcexport
```

## Metadata Options

```yaml
metadata:
  opc_hostname: the hostname of the OPC server from the topology file.
  elastic_ip: the ip address of the host with Elasticsearch. Defaults to 172.16.0.254.
  elastic_port: the Elasticsearch port. Defaults to 9200.
```

## Stages
> NOTE: The `configure` stage installs everything needed to run `opcexport` on the OPC and creates the `opcexport` config file from the OPC config file. The `start` stage starts the actual `opcexport` Python process, `scada_to_elastic.py`. The `stop` stage stops the `python.exe` process for `scada_to_elastic.py`, and the `cleanup` stage deletes the data from Elasticsearch.

> NOTE: The `stop` and `cleanup` stages are **optional** depending on your needs. If you use the `cleanup` stage, your data will be **DELETED**. If you wish to keep the data, ensure you moved it elsewhere before cleanup.

## Example Configuration

```yaml
components:
  - name: myopcexportcomponet
    type: opcexport
    metadata:
      opc_hostname: opc
      elastic_ip: 172.16.111.1
      elastic_port: 9200
```
